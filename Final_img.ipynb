{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import scipy\n",
    "import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width, height: 864.0 480.0\n",
      "fps: 30.0\n",
      "frames count: 1690.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mif\u001b[39;00m ret :\n\u001b[0;32m     40\u001b[0m     template_kpts, template_desc \u001b[39m=\u001b[39m sift\u001b[39m.\u001b[39mdetectAndCompute(template_gray, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m---> 41\u001b[0m     query_kpts, query_desc \u001b[39m=\u001b[39m sift\u001b[39m.\u001b[39;49mdetectAndCompute(query_gray, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     42\u001b[0m     matches \u001b[39m=\u001b[39m bf\u001b[39m.\u001b[39mknnMatch(template_desc, query_desc, k\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     45\u001b[0m     good_matches \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture('left_output.avi')       #ดึงวิดิโอ\n",
    "template_img = cv2.imread('Template-1.png')      #ดึงรูปภาพ\n",
    "template_gray = cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)    #เปลี่ยนBGR เป็นgray\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "Xx=0\n",
    "Yy=0\n",
    "Zz=0\n",
    "width  = 0      \n",
    "height = 0  \n",
    "\n",
    "\n",
    "if video.isOpened(): \n",
    "    width  = video.get(3)  \n",
    "    height = video.get(4)  # float height\n",
    "    print('width, height:', width, height)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    # or\n",
    "fps = video.get(5)   \n",
    "print('fps:', fps)  # float `fps`\n",
    "frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    # or\n",
    "frame_count = video.get(7)\n",
    "    \n",
    "middle_w=width/2\n",
    "middle_h=height/2\n",
    "\n",
    "    \n",
    "print('frames count:', frame_count)  # float `frame_count`\n",
    "\n",
    "while video.isOpened() :\n",
    "    ret, query_img = video.read()\n",
    "    ret, img = video.read()\n",
    "    query_gray = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if ret :\n",
    "        \n",
    "        template_kpts, template_desc = sift.detectAndCompute(template_gray, None)\n",
    "        query_kpts, query_desc = sift.detectAndCompute(query_gray, None)\n",
    "        matches = bf.knnMatch(template_desc, query_desc, k=2)\n",
    "\n",
    "        \n",
    "        good_matches = list()\n",
    "        good_matches_list = list()\n",
    "\n",
    "        for m, n in matches :\n",
    "            if m.distance < 0.65*n.distance :\n",
    "                good_matches.append(m)\n",
    "                good_matches_list.append([m])\n",
    "        \n",
    "        if len(good_matches) > 8.5 :\n",
    "            src_pts = np.float32([ template_kpts[m.queryIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "            dst_pts = np.float32([ query_kpts[m.trainIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "            src_pts,dst_pts = np.float32((src_pts,dst_pts))\n",
    "            H, inlier_masks = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 1.5) # H RANSAC\n",
    "            # get the bounding box around template image\n",
    "            h, w = template_img.shape[:2]\n",
    "            template_box = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1,1,2)         \n",
    "            transformed_box = cv2.perspectiveTransform(template_box, H)\n",
    "            \n",
    "            detected_img = cv2.polylines(query_img, [np.int32(transformed_box)], True, (0,255,0), 3, cv2.LINE_AA)     #ตีกรอบ\n",
    "            \n",
    "            \n",
    "            X0 = transformed_box[0][0]\n",
    "            Y0 = transformed_box[1][0]\n",
    "            Z0 = 0\n",
    "\n",
    "            axis1=transformed_box[0]\n",
    "            axis2=transformed_box[1]\n",
    "            axissum=axis2[0]-axis1[0]\n",
    "           \n",
    "            \n",
    "            cv2.putText(query_img, \" x = {:.1f} m     y = {:.1f} m     z = {:.1f} m\".format(int(X0[0]-middle_w),int(Y0[1]-middle_h), \n",
    "            int(axissum[1])),(10,query_img.shape[0] - 20), cv2.FONT_ITALIC,1, (0, 255, 255), 2)\n",
    "            \n",
    "    \n",
    "            cv2.imshow('Video frame', detected_img)\n",
    "          \n",
    "\n",
    "        if cv2.waitKey(int(1)) & 0xFF == ord('q') : \n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5db8019398856702669e8c4bfb3e084312105b1c56d74e6353be5e0a5d9ff9d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
